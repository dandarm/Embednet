{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UTWMLwK3l_rO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5mAMhFjFl_rQ"
   },
   "outputs": [],
   "source": [
    "data = np.load('dataset_grafi_N300_compressed.npz')\n",
    "dataset_grafi_np = data['arr_0']\n",
    "dataset_grafi_np.shape\n",
    "\n",
    "Num_grafi_per_tipo = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpE0sddzl_rQ",
    "outputId": "53faf25e-621f-4c51-c397-0489ab6bff78"
   },
   "source": [
    "### Create Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iUIeXFVGl_rR",
    "outputId": "ebd422c6-9e31-407e-be1f-5fcca7cf513b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 200/200 [00:40<00:00,  4.94it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_pyg = []\n",
    "\n",
    "i = 0\n",
    "for g in tqdm(dataset_grafi_np,total = len(dataset_grafi_np)):\n",
    "    nx_graph = nx.from_numpy_matrix(g)\n",
    "    \n",
    "    # aggiungo i metadati x e y per l'oggetto Data di PYG\n",
    "    nodi = list(nx_graph.nodes)\n",
    "    for n in nodi:\n",
    "        nx_graph.nodes[n][\"x\"] = [1.0]\n",
    "       \n",
    "    pyg_graph = from_networkx(nx_graph)\n",
    "    type_graph = 0 if i < Num_grafi_per_tipo else 1\n",
    "    pyg_graph.y = torch.tensor([type_graph],dtype = torch.long)\n",
    "    \n",
    "    pyg_graph = pyg_graph.to(device)\n",
    "    dataset_pyg.append(pyg_graph)\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uzVUncHAl_rR",
    "outputId": "0a45162c-1ff8-4996-dde8-4202251cc317"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pyg[88].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EicYzoHwl_rS",
    "outputId": "fc00d203-e5b1-4932-e919-89cc3183c4b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 140\n",
      "DataBatch(x=[42000, 1], edge_index=[2, 3840670], weight=[3840670], y=[140], batch=[42000], ptr=[141])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(12345)\n",
    "import random\n",
    "\n",
    "#dataset_pyg = dataset_pyg.shuffle()\n",
    "random.shuffle(dataset_pyg)\n",
    "len_data = len(dataset_pyg)\n",
    "tt_split = int(len_data*0.7)\n",
    "train_dataset = dataset_pyg[:tt_split]\n",
    "test_dataset = dataset_pyg[tt_split:]\n",
    "\n",
    "bs = 200\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "iUruEPOMl_rS",
    "outputId": "1c65b02d-87f9-4fe3-df50-424ccfd7a80c"
   },
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch.x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0Vm50xCl_rV"
   },
   "source": [
    "# Model Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EMXoygG3l_rV",
    "outputId": "3a02c298-d83f-49d2-991b-04341d4a4477"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (conv3): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "node_features = 1\n",
    "num_classes = 2\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        #torch.manual_seed(12345)\n",
    "        \n",
    "        self.conv1 = GCNConv(node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gu4oVEEQl_rV"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "UtzACrRSl_rW",
    "outputId": "0dc2b3de-c811-4828-83e5-d968c47fc491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 002, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 003, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 004, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 005, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 006, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 007, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 008, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 009, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 010, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 011, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 012, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 013, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 014, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 015, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 016, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 017, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 018, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 019, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 020, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 021, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 022, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 023, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 024, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 025, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 026, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 027, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 028, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 029, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 030, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 031, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 032, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 033, Train Acc: 0.8786, Test Acc: 0.8167\n",
      "Epoch: 034, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 035, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 036, Train Acc: 0.5000, Test Acc: 0.5167\n",
      "Epoch: 037, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 038, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 039, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 040, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 041, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 042, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 043, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 044, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 045, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 046, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 047, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 048, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 049, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 050, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 051, Train Acc: 0.7714, Test Acc: 0.7833\n",
      "Epoch: 052, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 053, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 054, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 055, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 056, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 057, Train Acc: 0.6714, Test Acc: 0.7000\n",
      "Epoch: 058, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 059, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 060, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 061, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 062, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 063, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 064, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 065, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 066, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 067, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 068, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 069, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 070, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 071, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 072, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 073, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 074, Train Acc: 0.7071, Test Acc: 0.7500\n",
      "Epoch: 075, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 076, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 077, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 078, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 079, Train Acc: 0.5214, Test Acc: 0.5500\n",
      "Epoch: 080, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 081, Train Acc: 1.0000, Test Acc: 0.9833\n",
      "Epoch: 082, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 083, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 084, Train Acc: 0.5214, Test Acc: 0.5333\n",
      "Epoch: 085, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 086, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 087, Train Acc: 0.9929, Test Acc: 0.9833\n",
      "Epoch: 088, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 089, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 090, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 091, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 092, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 093, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 094, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 095, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 096, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 097, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 098, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 099, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 100, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 101, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 102, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 103, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 104, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 105, Train Acc: 0.4929, Test Acc: 0.5167\n",
      "Epoch: 106, Train Acc: 0.9929, Test Acc: 1.0000\n",
      "Epoch: 107, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 108, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 109, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 110, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 111, Train Acc: 0.6071, Test Acc: 0.6833\n",
      "Epoch: 112, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 113, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 114, Train Acc: 0.6571, Test Acc: 0.7000\n",
      "Epoch: 115, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 116, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 117, Train Acc: 0.5071, Test Acc: 0.5333\n",
      "Epoch: 118, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 119, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 120, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 121, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 122, Train Acc: 0.5714, Test Acc: 0.6333\n",
      "Epoch: 123, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 124, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 125, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 126, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 127, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 128, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 129, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 130, Train Acc: 0.9786, Test Acc: 0.9333\n",
      "Epoch: 131, Train Acc: 0.5071, Test Acc: 0.4833\n",
      "Epoch: 132, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 133, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 134, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 135, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 136, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 137, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 138, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 139, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 140, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 141, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 142, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 143, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 144, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 145, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 146, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 147, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 148, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 149, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 150, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 151, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 152, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 153, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 154, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 155, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 156, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 157, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 158, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 159, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 160, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 161, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 162, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 163, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 164, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 165, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 166, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 167, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 168, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 169, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 170, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 171, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 172, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 173, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 174, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 175, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 176, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 177, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 178, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 179, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 180, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 181, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 182, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 183, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 184, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 185, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 186, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 187, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 188, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 189, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 190, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 191, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 192, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 193, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 194, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 195, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 196, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 197, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 198, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Epoch: 199, Train Acc: 1.0000, Test Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 200):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Children Counter:  0  Layer Name:  conv1\n",
      "Children Counter:  1  Layer Name:  conv2\n",
      "Children Counter:  2  Layer Name:  conv3\n",
      "Children Counter:  3  Layer Name:  lin\n"
     ]
    }
   ],
   "source": [
    "children_counter = 0\n",
    "for n,c in model.named_children():\n",
    "    print(\"Children Counter: \",children_counter,\" Layer Name: \",n,)\n",
    "    children_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1', GCNConv(1, 64)),\n",
       "             ('conv2', GCNConv(64, 64)),\n",
       "             ('conv3', GCNConv(64, 64)),\n",
       "             ('lin', Linear(in_features=64, out_features=2, bias=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "model2 = copy.deepcopy(model)\n",
    "\n",
    "if \"embedding_model\" in locals(): \n",
    "    del(embedding_model)\n",
    "\n",
    "class embedding_model(torch.nn.Module):\n",
    "    def __init__(self, old_model):\n",
    "        super().__init__()\n",
    "        #old_layers = list(old_model._modules.keys())\n",
    "        #old_model._modules.pop(old_layers[-1])\n",
    "        #self.net = torch.nn.Sequential(old_model)\n",
    "        \n",
    "        self.conv1 = old_model._modules['conv1']\n",
    "        self.conv2 = old_model._modules['conv2']\n",
    "        self.conv3 = old_model._modules['conv3']\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)##\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "     \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding_model(model2)\n",
    "embedding = embedding.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_loader = DataLoader(dataset_pyg, batch_size=len_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(all_data_loader))\n",
    "batch.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = embedding(batch.x, batch.edge_index, batch.batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 64]), 200, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape, len_data, len(dataset_pyg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = res.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniele/anaconda3/envs/pytorch-geom/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/daniele/anaconda3/envs/pytorch-geom/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(X_tsne[:,0], X_tsne[:,1], alpha=0.8, s=8)#, c=y)\n",
    "plt.xlabel('1st tsne component')\n",
    "plt.ylabel('2nd tsne component')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "rqF1TWBGl_rW"
   },
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "def create_graphs(p_er,type_graph):\n",
    "\tN = 1_000 # Graph nodes number\n",
    "\tNum_grafi_per_tipo = 1_00 # number of graphs\n",
    "\tgraphs = []\n",
    "\tfor i in tqdm(range(Num_grafi_per_tipo),total = Num_grafi_per_tipo):\n",
    "\t\tgr_er = nx.erdos_renyi_graph(N, p_er)\n",
    "\t\tnodes_gr_er = list(gr_er.nodes())\n",
    "\t\tfor node in nodes_gr_er:\n",
    "\t\t\tgr_er.nodes[node][\"x\"] = [1.0]\n",
    "\t\td0 = from_networkx(gr_er)\n",
    "\t\ttarget = torch.tensor([type_graph],dtype = torch.long)\n",
    "\t\td0.y = target\n",
    "\t\tgraphs.append(d0)\n",
    "\treturn graphs\n",
    "\n",
    "g1 = create_graphs(0.01,0.0)\n",
    "g2 = create_graphs(0.3,1.0)\n",
    "all_graphs = g1+g2\n",
    "d0 = all_graphs[0]\n",
    "print(d0)\n",
    "print(f'Number of nodes: {d0.num_nodes}')\n",
    "print(f'Number of edges: {d0.num_edges}')\n",
    "\n",
    "tt_split = int(len(all_graphs)*0.7)\n",
    "print(tt_split)\n",
    "train_dataset = all_graphs[:tt_split]\n",
    "test_dataset = all_graphs[tt_split:]\n",
    "print(len(train_dataset))\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False)\n",
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "\n",
    "node_features = 1\n",
    "num_classes = 2\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=64)\n",
    "print(model)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "for epoch in range(1, 171):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GNN_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-geom]",
   "language": "python",
   "name": "conda-env-pytorch-geom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
