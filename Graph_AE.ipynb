{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255c05f6-896d-4df1-91f6-852156ee98ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "! git clone https://github.com/Pangyk/Graph_AE.git "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636527bd-f820-4b85-b1f1-8a2a2d4db2a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "! pip install pandas\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b802b1b-8f55-4694-8952-fce5ccc7cba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "#sys.path.append('/workspace/Embednet/')\n",
    "#sys.path.append('/workspace/Graph_AE/')\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30a400b-42f7-424c-9b18-76b57fa104b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUBLAS_WORKSPACE_CONFIG=\":4096:8\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 19:17:25.138111: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 19:17:25.929904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'array_wo_outliers' from 'utils' (/workspace/Embednet/../Graph_AE/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplot_funcs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (plot_dim1, plot_dimN, plot_correlation_error, plot_metrics, plot_node_emb_1D, plot_node_emb_nD, scatter_node_emb, \n\u001b[1;32m     29\u001b[0m                         plot_graph_emb_1D, plot_graph_emb_nD, plot_data_degree_sequence, plot_corr_epoch, plot_ripetizioni_stesso_trial, \n\u001b[1;32m     30\u001b[0m                         plot_onlyloss_ripetizioni_stesso_trial,plot_onlyloss_ripetizioni_stesso_trial_superimposed, Data2Plot, plot_weights_multiple_hist)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplot_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array_wo_outliers, plot_grafo, plot_grafo2\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mInspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Inspect\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'array_wo_outliers' from 'utils' (/workspace/Embednet/../Graph_AE/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#per la riproducibilità\n",
    "%env CUBLAS_WORKSPACE_CONFIG=\":4096:8\"\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from IPython.display import Markdown as md\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from networkx import stochastic_block_model\n",
    "\n",
    "import torch_geometric\n",
    "from graph_generation import GenerateGraph, perturb_nx_graph\n",
    "from models import GCN, view_parameters, new_parameters, modify_parameters, Inits, new_parameters_linears\n",
    "from train import Trainer, Dataset\n",
    "from embedding import Embedding\n",
    "from config_valid import Config, TrainingMode\n",
    "import experiments\n",
    "from experiments import Experiments, all_seeds\n",
    "from plot_funcs import (plot_dim1, plot_dimN, plot_correlation_error, plot_metrics, plot_node_emb_1D, plot_node_emb_nD, scatter_node_emb, \n",
    "                        plot_graph_emb_1D, plot_graph_emb_nD, plot_data_degree_sequence, plot_corr_epoch, plot_ripetizioni_stesso_trial, \n",
    "                        plot_onlyloss_ripetizioni_stesso_trial,plot_onlyloss_ripetizioni_stesso_trial_superimposed, Data2Plot, plot_weights_multiple_hist)\n",
    "from plot_model import plot_model\n",
    "from utils import array_wo_outliers, plot_grafo, plot_grafo2\n",
    "from Inspect import Inspect\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch_geometric import nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "device = torch.device('cuda')\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import pickle \n",
    "from plt_parameters import init_params, get_colors_to_cycle_rainbow8, get_colors_to_cycle_rainbowN\n",
    "init_params()\n",
    "rootsave = Path(\"output_plots/\")\n",
    "\n",
    "def make_video_parallel_static():\n",
    "    experiments.graph_embedding_per_epoch = xp.trainer.graph_embedding_per_epoch\n",
    "    experiments.node_embedding_per_epoch = xp.trainer.node_embedding_per_epoch\n",
    "    experiments.dataset = xp.trainer.dataset\n",
    "    experiments.loss_list = xp.trainer.test_loss_list\n",
    "    experiments.exp_config = xp.trainer.config_class\n",
    "    experiments.dataset_type = xp.trainer.gg.graphtype\n",
    "    num_emb_neurons = xp.trainer.model.convs[-1].out_channels\n",
    "    experiments.trainmode = xp.trainer.config_class.modo\n",
    "    #experiments.num_classes = xp.trainer.config_class.num_classes\n",
    "    experiments.embedding_dimension = num_emb_neurons\n",
    "    #my_list = my_log_lista=list(range(20)) + list(range(20,100,4)) + list(range(100,500, 15)) + list(range(500, 5000, 40))\n",
    "    nomefile = xp.make_video(skip=1, fromfiles=True, custom_list=True, seq_colors=True)\n",
    "    return nomefile\n",
    "\n",
    "\n",
    "def run_grid_w_gif(xp):\n",
    "    nomifilesgif = []\n",
    "    k = 0\n",
    "    for c in xp.gc.configs:  \n",
    "        print(f'Run {k + 1}\\t\\t exp name: {c.unique_train_name}')\n",
    "        # all_seeds()\n",
    "        xp.trainer.reinit_conf(c)\n",
    "        xp.just_train()\n",
    "        embedding_class = xp.embedding()\n",
    "        num_emb_neurons = xp.trainer.model.convs[-1].out_channels\n",
    "        trainmode = xp.trainer.config_class.modo\n",
    "        embedding_class.get_metrics(num_emb_neurons, trainmode)    \n",
    "        nomefile = make_video_parallel_static()\n",
    "        nomifilesgif.append(nomefile)\n",
    "        k += 1\n",
    "    return nomifilesgif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e959af55-7521-406e-a46a-44d67692bdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Embednet\n"
     ]
    }
   ],
   "source": [
    "%cd Embednet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5096dcc0-0799-4ba2-bd56-e4b1c13f1d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 configurazioni saltate su 3, farò i seguenti 1 training:\n",
      "GraphType.SBM_Classi3_nodi900_grafiXtipo250_mode1_layers§1-128-64§_initw-xavier_normal_lr0.002_GCNfreezedFalse\n"
     ]
    }
   ],
   "source": [
    "config_file = \"configurations/Final1.yml\"\n",
    "num_nodi = 900\n",
    "c = Config(config_file)\n",
    "c.conf['graph_dataset']['Num_nodes'] = num_nodi\n",
    "c.conf['graph_dataset']['list_exponents'] = [-2.5]\n",
    "c.conf['model']['autoencoder'] = False\n",
    "c.conf['model']['autoencoder_graph_ae'] = True\n",
    "diz_trials = {'graph_dataset.ERmodel': [False], 'graph_dataset.confmodel': [False], 'graph_dataset.sbm': [False], 'graph_dataset.sbm': [True],\n",
    "              'graph_dataset.Num_nodes': [[num_nodi], [num_nodi]*7, [num_nodi]*2],  # per lo SBM: num nodi * num comunità \n",
    "              'model.GCNneurons_per_layer': [#[1, 32, 16, len(c.conf['graph_dataset']['list_exponents'])],\n",
    "                                            #[1, 32, 16, len(c.conf['graph_dataset']['list_p'])],\n",
    "                                            #[1, 32, 16, len(c.conf['graph_dataset']['community_probs'])],\n",
    "                                            [1, 128, 64]\n",
    "                                           ],\n",
    "             'model.init_weights': ['xavier_normal'],# 'eye'],\n",
    "             'model.freezeGCNlayers': [False],\n",
    "             'model.last_layer_dense': [False],\n",
    "             } \n",
    "\n",
    "xp = Experiments(diz_trials=diz_trials, rootsave=rootsave, config_class=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a63a3629-ab2e-49ab-85f1-36c037ca3b76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 \t\t exp name: GraphType.SBM_Classi3_nodi900_grafiXtipo250_mode1_layers§1-128-64§_initw-xavier_normal_lr0.002_GCNfreezedFalse\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGS_simple_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Embednet/experiments.py:133\u001b[0m, in \u001b[0;36mExperiments.GS_simple_experiments\u001b[0;34m(self, list_points, parallel_take_result)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# all_seeds()\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mreinit_conf(c)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjust_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m embedding_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding()\n\u001b[1;32m    136\u001b[0m embedding_dimension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconvs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mout_channels\n",
      "File \u001b[0;32m/workspace/Embednet/experiments.py:401\u001b[0m, in \u001b[0;36mExperiments.just_train\u001b[0;34m(self, parallel, verbose)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjust_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, parallel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlaunch_training()\n",
      "File \u001b[0;32m/workspace/Embednet/train.py:186\u001b[0m, in \u001b[0;36mTrainer.init_all\u001b[0;34m(self, parallel, verbose)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mInizializza modello e datasest\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m:param parallel:\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m:param verbose: se True ritorna il plot object del model\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m init_weigths_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;241m.\u001b[39minit_weights_mode\n\u001b[0;32m--> 186\u001b[0m w \u001b[38;5;241m=\u001b[39m new_parameters(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_GCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, init_weigths_method)\n\u001b[1;32m    187\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_GCN(init_weights_gcn\u001b[38;5;241m=\u001b[39mw, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(model)\n",
      "File \u001b[0;32m/workspace/Embednet/train_autoencoderMIAGAE.py:36\u001b[0m, in \u001b[0;36mTrainer_AutoencoderMIAGAE.init_GCN\u001b[0;34m(self, init_weights_gcn, init_weights_lin, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoencoderMIAGAE\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m#if init_weights_gcn is not None:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#    modify_parameters(model, init_weights_gcn)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#if init_weights_lin is not None:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#    modify_parameters_linear(model, init_weights_lin)\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/Embednet/model_MIAGAE.py:41\u001b[0m, in \u001b[0;36mAutoencoderMIAGAE.__init__\u001b[0;34m(self, config_class, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m GCNneurons_per_layer \u001b[38;5;241m=\u001b[39m graph_ae_configs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGCNneurons_per_layer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     40\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mMIAGAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGCNneurons_per_layer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_kernels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcomp_rate\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGCNneurons_per_layer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/workspace/Graph_AE/classification/Graph_AE.py:29\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self, input_size, kernels, depth, rate, shapes, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m     pool \u001b[38;5;241m=\u001b[39m TopKPooling(shapes[i], rate[i])\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_list\u001b[38;5;241m.\u001b[39mappend(pool)\n\u001b[0;32m---> 29\u001b[0m     conv \u001b[38;5;241m=\u001b[39m SGAT(size, shapes[i], \u001b[43mshapes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_list\u001b[38;5;241m.\u001b[39mappend(conv)\n\u001b[1;32m     31\u001b[0m pool \u001b[38;5;241m=\u001b[39m TopKPooling(shapes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], rate[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "xp.GS_simple_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c396d93-6803-46d4-bce0-c15e0adf6441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061c133-f094-47ed-8b9f-0701e0309cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd690e9-e7e2-464e-a114-bd7e47577063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0b3e6-cd74-417a-b06d-8b36259d73bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f54f5-8fee-448e-974a-5180f1382c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9f8d8-1fb5-402e-9c3e-5e85a6a9887b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f97859-dfa5-44f9-9036-b3052723e626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8454fb01-b3ad-4319-8978-b39632cfd4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eafd6d1-526e-4c2d-a559-c3da5036502e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace',\n",
       " '/usr/lib/python310.zip',\n",
       " '/usr/lib/python3.10',\n",
       " '/usr/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.10/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " 'Embednet/',\n",
       " 'Graph_AE/',\n",
       " '/workspace/Embednet/',\n",
       " '/workspace/Graph_AE/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e869ae5-4b69-4d48-9bae-693ee7331150",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c0012-0752-49ad-8708-28efe1d8352a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from Graph_AE.utils.CustomDataSet import SelectGraph\n",
    "from Graph_AE.utils.train_utils import train_cp\n",
    "import torch\n",
    "import argparse\n",
    "import sys\n",
    "#sys.path.append('/workspace/Embednet/')\n",
    "sys.path.append('/workspace/Graph_AE/')\n",
    "\n",
    "#%env 'PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128'\n",
    "#%env CUBLAS_WORKSPACE_CONFIG=\":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c239ca44-c76e-42c7-a7b9-52e742832c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(d='REDDIT-BINARY', m='MIAGAE', device='cuda', batch=512, e=100, lr=0.001, model_dir='data/model/', n_train=1500, n_test=1000, k=2, depth=3, c_rate=0.8, shapes='64,64,64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Global_Dict generator')\n",
    "parser.add_argument('--d', type=str, default='FRANKENSTEIN', help=\"dataset name\")\n",
    "parser.add_argument('--m', type=str, default='MIAGAE', help=\"model name\")\n",
    "parser.add_argument('--device', type=str, default='cuda', help=\"cuda / cpu\")\n",
    "parser.add_argument('--batch', type=int, default=512, help=\"batch size\")\n",
    "parser.add_argument('--e', type=int, default=100, help=\"number of epochs\")\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"learning rate\")\n",
    "parser.add_argument('--model_dir', type=str, default=\"data/model/\", help=\"path to save model\")\n",
    "parser.add_argument('--n_train', type=int, default=3000, help=\"number of samples for train set\")\n",
    "parser.add_argument('--n_test', type=int, default=1000, help=\"number of samples for test set\")\n",
    "parser.add_argument('--k', type=int, default=2, help=\"number of kernels\")\n",
    "parser.add_argument('--depth', type=int, default=3, help=\"depth of encoder and decoder\")\n",
    "parser.add_argument('--c_rate', type=float, default=0.8, help=\"compression ratio for each layer of encoder\")\n",
    "parser.add_argument('--shapes', type=str, default=\"64,64,64\", help=\"shape of each layer in encoder\")\n",
    "#args = parser.parse_args()\n",
    "sys.argv = ['--d','REDDIT-BINARY', '--n_train', '1500', '--e', '100']\n",
    "args = parser.parse_args(sys.argv)\n",
    "#args = parser.parse_args(['--d', 'COLORS-3'])\n",
    "#args = parser.parse_args([])\n",
    "args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a24e02c-b14a-4aff-819c-649e960cd6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {'d':'REDDIT-BINARY','m':'MIAGAE', 'device':'cuda', 'batch':512, 'e':100, 'lr':0.001, 'model_dir':'data/model/', 'n_train':1500, 'n_test':1000, 'k':2, 'depth':3, 'c_rate':0.8, 'shapes':'64,64,64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4068c-a031-414e-beed-3c668912bc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(args.device)\n",
    "\n",
    "num_epoch = args.e\n",
    "batch_size = args.batch\n",
    "\n",
    "SelectGraph.data_name = args.d\n",
    "data_set = SelectGraph('data/' + SelectGraph.data_name)\n",
    "\n",
    "#check sulle feature\n",
    "dataset_mod = []\n",
    "for d in data_set:\n",
    "    if d.x is None:\n",
    "        d.x = torch.ones([d.num_nodes], dtype=torch.float).unsqueeze(1) \n",
    "    dataset_mod.append(d)\n",
    "\n",
    "    \n",
    "train_set = DataLoader(dataset_mod[:args.n_train], batch_size=batch_size, shuffle=True)\n",
    "test_set = DataLoader(dataset_mod[args.n_train:args.n_train + args.n_test], batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7010db8b-93eb-4e25-96d5-9177b987e4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "input_size = 1 # data_set.num_features\n",
    "print(input_size)\n",
    "shapes = list(map(int, args.shapes.split(\",\")))\n",
    "if args.m == \"MIAGAE\":\n",
    "    from classification.Graph_AE import Net\n",
    "    model = Net(input_size, args.k, args.depth, [args.c_rate] * args.depth, shapes, device).to(device)\n",
    "elif args.m == \"UNet\":\n",
    "    from classification.UNet import Net\n",
    "    model = Net(input_size, args.depth, args.c_rate, shapes, device).to(device)\n",
    "elif args.m == \"Gpool\":\n",
    "    from classification.Gpool_model import Net\n",
    "    model = Net(input_size, args.depth, args.c_rate, shapes, device).to(device)\n",
    "elif args.m == \"SAGpool\":\n",
    "    from classification.SAG_model import Net\n",
    "    model = Net(input_size, args.depth, [args.c_rate] * args.depth, shapes, device).to(device)\n",
    "else:\n",
    "    print(\"model not found\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120700d8-7b8d-48b2-9225-162c33a6ebbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 23.65 GiB total capacity; 21.54 GiB already allocated; 63.69 MiB free; 22.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_cp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Graph_AE/utils/train_utils.py:37\u001b[0m, in \u001b[0;36mtrain_cp\u001b[0;34m(model, optimizer, device, train_set, valid_set, num_epoch, path, m_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     36\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 37\u001b[0m z, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()(z, data\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m     40\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/Graph_AE/classification/Graph_AE.py:63\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth:\n\u001b[1;32m     62\u001b[0m     edge_list\u001b[38;5;241m.\u001b[39mappend(e)\n\u001b[0;32m---> 63\u001b[0m f, attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m shape_list\u001b[38;5;241m.\u001b[39mappend(f\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     65\u001b[0m f \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(f)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/Graph_AE/graph_ae/Layer.py:45\u001b[0m, in \u001b[0;36mSGAT.forward\u001b[0;34m(self, x, edge_index, direction)\u001b[0m\n\u001b[1;32m     43\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat_list:\n\u001b[0;32m---> 45\u001b[0m     feature, attn \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         feature_list \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mleaky_relu(feature)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/Graph_AE/graph_ae/SAGEAttn.py:69\u001b[0m, in \u001b[0;36mSAGEAttn.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, x_norm\u001b[38;5;241m=\u001b[39mx_norm, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print(f\"out: {out.shape}, lin: {self.lin_l}\")\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin_l\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 70.00 MiB (GPU 0; 23.65 GiB total capacity; 21.54 GiB already allocated; 63.69 MiB free; 22.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_cp(model, optimizer, device, train_set, test_set, num_epoch, args.model_dir, args.m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b1106-7f2f-4e83-9936-ea16f99a1d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6f8575-c28a-4bdf-8342-c96e8f0d8eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e775ad39-a447-4aee-9d94-2619c598f3fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l =  torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d493ec09-c2eb-4656-8e0a-9147a13f090b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0684)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 5)\n",
    "b = torch.randn(3, 5)\n",
    "l(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f128373d-c2fc-462b-839d-075e68b2846f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5887)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss()(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ce498ec-e0a8-4c91-a5b0-b52e75171b56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones([10]).unsqueeze(1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
