{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from graph_generation import create_ER, dataset_nclass_ER, dataset_regression_ER\n",
    "from models import GCN\n",
    "from train import Trainer, Dataset\n",
    "from embedding import Embedding\n",
    "from experiments import experiment_embedding, train_take_embedding, plot_dim1, plot_dimN, plot_correlation_error\n",
    "from config_valid import Config, TrainingMode\n",
    "\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(1, 8)\n",
      "    (1): GCNConv(8, 1)\n",
      "  )\n",
      "  (lin): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (leakys): ModuleList(\n",
      "    (0): LeakyReLU(negative_slope=0.03)\n",
      "    (1): LeakyReLU(negative_slope=0.03)\n",
      "    (2): LeakyReLU(negative_slope=0.03)\n",
      "  )\n",
      "  (mean_pool): MeanAggregation()\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Generating dataset...\n",
      "Mean connectivity for each node: 14.978 p=0.05\n",
      "Mean connectivity for each node: 89.633 p=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 60/60 [00:04<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo impiegato: 4.126057863235474\n",
      "tensor([0.2958], device='cuda:0') 54\n",
      "tensor([0.3006], device='cuda:0') 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_c = Config(\"configs.yml\")\n",
    "config_c.load_conf()\n",
    "config_c.valid_conf()\n",
    "\n",
    "\n",
    "\n",
    "model = GCN(config_c)\n",
    "model.to('cuda')\n",
    "print(model)\n",
    "\n",
    "modo = config_c.get_mode()\n",
    "if modo == TrainingMode.mode1 or modo == TrainingMode.mode2:\n",
    "    dataset, list_p = dataset_nclass_ER(config_c)\n",
    "if modo == TrainingMode.mode3:\n",
    "    dataset, list_p = dataset_regression_ER(config_c)\n",
    "ds = Dataset.from_super_instance(0.9, 90, 'cuda', config_c.conf, dataset)\n",
    "ds.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = ds.dataset_pyg\n",
    "all_data_loader = DataLoader(whole_data, batch_size=ds.bs, shuffle=False)\n",
    "model.eval()\n",
    "#trainer.model.train()\n",
    "batch = next(iter(all_data_loader))\n",
    "writer = SummaryWriter(\"./runs/grafi_NN\")\n",
    "writer.add_graph(model, (batch.x, batch.edge_index), verbose=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a9e33742a82c7b2a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a9e33742a82c7b2a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "whole_data = trainer.dataset.dataset_pyg\n",
    "all_data_loader = DataLoader(whole_data, batch_size=trainer.dataset.bs, shuffle=False)\n",
    "trainer.model.eval()\n",
    "#trainer.model.train()\n",
    "batch = next(iter(all_data_loader))\n",
    "out = trainer.model(batch.x, batch.edge_index, batch.batch, embedding=False)\n",
    "\n",
    "make_dot(out.mean(), params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esempio con tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_input = (torch.zeros(1, 3),)\n",
    "\n",
    "\n",
    "class LinearInLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearInLinear, self).__init__()\n",
    "        self.l = nn.Linear(3, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l(x)\n",
    "\n",
    "with SummaryWriter(comment='LinearInLinear') as w:\n",
    "    w.add_graph(LinearInLinear(), dummy_input, True)\n",
    "\n",
    "\n",
    "class MultipleInput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultipleInput, self).__init__()\n",
    "        self.Linear_1 = nn.Linear(3, 5)\n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.Linear_1(x+y)\n",
    "\n",
    "with SummaryWriter(comment='MultipleInput') as w:\n",
    "    w.add_graph(MultipleInput(), (torch.zeros(1, 3), torch.zeros(1, 3)), True)\n",
    "\n",
    "class MultipleOutput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultipleOutput, self).__init__()\n",
    "        self.Linear_1 = nn.Linear(3, 5)\n",
    "        self.Linear_2 = nn.Linear(3, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Linear_1(x), self.Linear_2(x)\n",
    "\n",
    "with SummaryWriter(comment='MultipleOutput') as w:\n",
    "    w.add_graph(MultipleOutput(), dummy_input, True)\n",
    "\n",
    "\n",
    "class MultipleOutput_shared(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultipleOutput_shared, self).__init__()\n",
    "        self.Linear_1 = nn.Linear(3, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.Linear_1(x), self.Linear_1(x)\n",
    "\n",
    "with SummaryWriter(comment='MultipleOutput_shared') as w:\n",
    "    w.add_graph(MultipleOutput_shared(), dummy_input, True)\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * 2\n",
    "\n",
    "\n",
    "model = SimpleModel()\n",
    "dummy_input = (torch.zeros(1, 2, 3),)\n",
    "\n",
    "with SummaryWriter(comment='constantModel') as w:\n",
    "    w.add_graph(model, dummy_input, True)\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "dummy_input = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "with SummaryWriter(comment='basicblock') as w:\n",
    "    model = BasicBlock(3, 3)\n",
    "    w.add_graph(model, (dummy_input, ), verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2)\n",
    "        x = F.relu(x) + F.relu(-x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.bn(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "dummy_input = Variable(torch.rand(13, 1, 28, 28))\n",
    "\n",
    "model = Net1()\n",
    "with SummaryWriter(comment='Net1') as w:\n",
    "    w.add_graph(model, (dummy_input, ))\n",
    "\n",
    "model = Net2()\n",
    "with SummaryWriter(comment='Net2') as w:\n",
    "    w.add_graph(model, (dummy_input, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = Net1()\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "\n",
    "model = SiameseNetwork()\n",
    "with SummaryWriter(comment='SiameseNetwork') as w:\n",
    "    w.add_graph(model, (dummy_input, dummy_input))\n",
    "\n",
    "\n",
    "dummy_input = torch.Tensor(1, 3, 224, 224)\n",
    "\n",
    "with SummaryWriter(comment='alexnet') as w:\n",
    "    model = torchvision.models.alexnet()\n",
    "    w.add_graph(model, (dummy_input, ))\n",
    "\n",
    "with SummaryWriter(comment='vgg19') as w:\n",
    "    model = torchvision.models.vgg19()\n",
    "    w.add_graph(model, (dummy_input, ))\n",
    "\n",
    "with SummaryWriter(comment='densenet121') as w:\n",
    "    model = torchvision.models.densenet121()\n",
    "    w.add_graph(model, (dummy_input, ))\n",
    "\n",
    "with SummaryWriter(comment='resnet18') as w:\n",
    "    model = torchvision.models.resnet18()\n",
    "    w.add_graph(model, (dummy_input, ))\n",
    "\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(\n",
    "            n_categories +\n",
    "            input_size +\n",
    "            hidden_size,\n",
    "            hidden_size)\n",
    "        self.i2o = nn.Linear(\n",
    "            n_categories +\n",
    "            input_size +\n",
    "            hidden_size,\n",
    "            output_size)\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1)\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden, input\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "\n",
    "n_letters = 100\n",
    "n_hidden = 128\n",
    "n_categories = 10\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "cat = torch.Tensor(1, n_categories)\n",
    "dummy_input = torch.Tensor(1, n_letters)\n",
    "hidden = torch.Tensor(1, n_hidden)\n",
    "\n",
    "\n",
    "out, hidden, input = rnn(cat, dummy_input, hidden)\n",
    "with SummaryWriter(comment='RNN') as w:\n",
    "    w.add_graph(rnn, (cat, dummy_input, hidden), verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "lstm = torch.nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "with SummaryWriter(comment='lstm') as w:\n",
    "    w.add_graph(lstm, (torch.randn(1, 3).view(1, 1, -1), hidden), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "print('expect error here:')\n",
    "with pytest.raises(Exception) as e_info:\n",
    "    dummy_input = torch.rand(1, 1, 224, 224)\n",
    "    with SummaryWriter(comment='basicblock_error') as w:\n",
    "        w.add_graph(model, (dummy_input, ))  # error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifica differenza layer dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model1(nn.Module):\n",
    "    # Model 1 using functional dropout\n",
    "    def __init__(self, p=0.0):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return nn.functional.dropout(inputs, p=self.p, training=True)\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    # Model 2 using dropout module\n",
    "    def __init__(self, p=0.0):\n",
    "        super().__init__()\n",
    "        self.drop_layer = nn.Dropout(p=p)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.drop_layer(inputs)\n",
    "model1 = Model1(p=0.1) # functional dropout \n",
    "model2 = Model2(p=0.1) # dropout module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1189, 0.8991, 0.4356, 0.2209, 0.2069, 0.1514, 0.9957, 0.7391, 0.0204,\n",
      "        0.8390])\n",
      "Normal (train) model:\n",
      "Model 1 tensor([0.1321, 0.9990, 0.0000, 0.0000, 0.2299, 0.1682, 1.1063, 0.8212, 0.0227,\n",
      "        0.9322])\n",
      "Model 2 tensor([0.1321, 0.9990, 0.4840, 0.2454, 0.2299, 0.1682, 1.1063, 0.8212, 0.0227,\n",
      "        0.9322])\n",
      "\n",
      "Evaluation mode:\n",
      "Model 1 tensor([0.1321, 0.9990, 0.4840, 0.2454, 0.2299, 0.1682, 1.1063, 0.0000, 0.0227,\n",
      "        0.9322])\n",
      "Model 2 tensor([0.1189, 0.8991, 0.4356, 0.2209, 0.2069, 0.1514, 0.9957, 0.7391, 0.0204,\n",
      "        0.8390])\n",
      "Print summary:\n",
      "Model1()\n",
      "Model2(\n",
      "  (drop_layer): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creating inputs\n",
    "inputs = torch.rand(10)\n",
    "print(inputs)\n",
    "# forwarding inputs in train mode\n",
    "print('Normal (train) model:')\n",
    "print('Model 1', model1(inputs))\n",
    "print('Model 2', model2(inputs))\n",
    "print()\n",
    "\n",
    "# switching to eval mode\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "# forwarding inputs in evaluation mode\n",
    "print('Evaluation mode:')\n",
    "print('Model 1', model1(inputs))\n",
    "print('Model 2', model2(inputs))\n",
    "# show model summary\n",
    "print('Print summary:')\n",
    "print(model1)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifica del pool mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.aggr.basic import MeanAggregation\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ma = MeanAggregation()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return ma(inputs)\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return global_mean_pool(inputs, None)\n",
    "    \n",
    "model1 = Model1() \n",
    "model2 = Model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
       "        0.2989])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
       "         0.2989]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal (train) model:\n",
      "Model 1 tensor([[0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
      "         0.2989]])\n",
      "Model 2 tensor([[0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
      "         0.2989]])\n",
      "\n",
      "Evaluation mode:\n",
      "Model 1 tensor([[0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
      "         0.2989]])\n",
      "Model 2 tensor([[0.5269, 0.5517, 0.4942, 0.4480, 0.5506, 0.4963, 0.6618, 0.4219, 0.5909,\n",
      "         0.2989]])\n",
      "Print summary:\n",
      "Model1(\n",
      "  (ma): MeanAggregation()\n",
      ")\n",
      "Model2()\n"
     ]
    }
   ],
   "source": [
    "# forwarding inputs in train mode\n",
    "print('Normal (train) model:')\n",
    "print('Model 1', model1(inputs))\n",
    "print('Model 2', model2(inputs))\n",
    "print()\n",
    "\n",
    "# switching to eval mode\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "# forwarding inputs in evaluation mode\n",
    "print('Evaluation mode:')\n",
    "print('Model 1', model1(inputs))\n",
    "print('Model 2', model2(inputs))\n",
    "\n",
    "# show model summary\n",
    "print('Print summary:')\n",
    "print(model1)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### codice sorgente per i due metodi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean_pool\n",
    "if batch is None:\n",
    "        return x.mean(dim=-2, keepdim=x.dim() == 2)\n",
    "    size = int(batch.max().item() + 1) if size is None else size\n",
    "return scatter(x, batch, dim=-2, dim_size=size, reduce='mean')\n",
    "\n",
    "\n",
    "\n",
    "def forward(self, x, index=None,ptr=None, dim_size=None, dim=-2):\n",
    "    return self.reduce(x, index, ptr, dim_size, dim, reduce='mean')\n",
    "\n",
    "class Aggregation\n",
    "def reduce(self, x, index=None, ptr=None, dim_size=None, dim=-2, reduce='add'):\n",
    "\n",
    "    if ptr is not None:\n",
    "        ptr = expand_left(ptr, dim, dims=x.dim())\n",
    "        return segment_csr(x, ptr, reduce=reduce)\n",
    "\n",
    "    assert index is not None\n",
    "    return scatter(x, index, dim=dim, dim_size=dim_size, reduce=reduce)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-geom]",
   "language": "python",
   "name": "conda-env-pytorch-geom-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
